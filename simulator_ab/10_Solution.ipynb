{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9669ecfa-f5cc-413c-b9b3-4e3d00b26d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _shared import *\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bca5bc-4b67-4578-a24d-96e90ba27672",
   "metadata": {},
   "source": [
    "## Задача 1. Количество параллельных экспериментов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e74e1-0941-40b6-bbb8-6125527e8ad7",
   "metadata": {},
   "source": [
    "Сколько несовместных независимых экспериментов можно запустить одновременно, если за время эксперимента собираем 10000 наблюдений?\n",
    "\n",
    "Если решаем запустить 10 экспериментов, то на каждый эксперимент можно выделить по 1000 наблюдений, размер групп будет равен 500.\n",
    "\n",
    "Параметры экспериментов:\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413bb73b-4d87-4c3e-af44-f044c3528539",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_num = 10_000\n",
    "test_ = stats.ttest_ind\n",
    "\n",
    "alpha_ = 0.05\n",
    "beta_ = 0.1\n",
    "effect_ = +0.03\n",
    "\n",
    "mean_ = 100.0\n",
    "std_ = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6afbce-4947-4156-bef2-bfc2ad867078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(np.random.normal(loc=mean_, scale=std_, size=obs_num), columns=['metric_a']) #Let index be the user_id.\n",
    "# df['metric_b'] = df['metric_a'] * (1 + effect_)\n",
    "\n",
    "# Number of test equals half the number of observation divided by required sample size (since we need 2 groups).\n",
    "res_1 = np.floor(obs_num / get_sample_size_rel(mu=mean_, std=std_, eff=effect_, alpha=alpha_, beta=beta_)) / 2\n",
    "res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef81e56-30b9-4587-b6e1-c0a7000e17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_experiment_design(number_of_experiments, N=10_000):\n",
    "    group_size = int((obs_num / number_of_experiments) / 2)\n",
    "    aa_res, ab_res = [], []\n",
    "    \n",
    "#    for _ in tqdm(range(N)):\n",
    "#         for i in range(number_of_experiments):\n",
    "#             a_beg = i * group_size * 2\n",
    "#             a_end = a_beg + group_size - 1\n",
    "#             b_beg = a_end + 1\n",
    "#             b_end = b_beg + group_size - 1\n",
    "\n",
    "#             aa_res.append(test_(metric_a[a_beg:a_end], metric_b[b_beg:b_end]).pvalue)\n",
    "#             ab_res.append(test_(metric_a[a_beg:a_end], metric_b_eff[b_beg:b_end]).pvalue)\n",
    "\n",
    "    for _ in tqdm(range(N)):\n",
    "        metric_a, metric_b = np.random.normal(loc=mean_, scale=std_, size=(2, group_size))\n",
    "        metric_b_eff = metric_b * (1.0 + effect_)\n",
    "\n",
    "        aa_res.append(test_(metric_a, metric_b).pvalue)\n",
    "        ab_res.append(test_(metric_a, metric_b_eff).pvalue)\n",
    "\n",
    "    return ((np.array(aa_res) < alpha_).mean(), (np.array(ab_res) >= alpha_).mean())\n",
    "\n",
    "\n",
    "res_string = '{:.0f}: I order: {:.4f} [{}]; II order: {:.4f} [{}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0cb7ca9-1c69-43c7-a17d-b770d8dc48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01854109764099121,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866f2706eee84d1da8cea351e5c19322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20: I order: 0.0482 [True]; II order: 0.0909 [True]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015732765197753906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ffc60f95b4793a1e2aaa4ac6f24a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21: I order: 0.0501 [False]; II order: 0.1055 [False]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015488862991333008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac5e982fccb421fb808e5e45a98e612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22: I order: 0.0499 [True]; II order: 0.1188 [False]\n"
     ]
    }
   ],
   "source": [
    "for n in (res_1-1, res_1, res_1+1):\n",
    "    p_i, p_ii = check_experiment_design(n, N=100_000)\n",
    "    print(res_string.format(n, p_i, p_i < alpha_, p_ii, p_ii < beta_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03823c64-d5e2-4698-ba54-4b2ad1018d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size = 233\n",
      "count_exp = 21.5\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016249656677246094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b953c28abc4c93a10fa8c761c20e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 21\n",
      "sample_size = 238\n",
      "оценка вероятности ошибки I рода = 0.0477\n",
      "  доверительный интервал = [0.0435, 0.0519]\n",
      "оценка вероятности ошибки II рода = 0.0996\n",
      "  доверительный интервал = [0.0937, 0.1055]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014811277389526367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d0bbbef1a4456dac5a2cacc4962b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 22\n",
      "sample_size = 227\n",
      "оценка вероятности ошибки I рода = 0.0505\n",
      "  доверительный интервал = [0.0462, 0.0548]\n",
      "оценка вероятности ошибки II рода = 0.1221\n",
      "  доверительный интервал = [0.1157, 0.1285]\n"
     ]
    }
   ],
   "source": [
    "# Solution.\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# параметры эксперимента\n",
    "total_size = 10000\n",
    "mean_ = 100\n",
    "std_ = 10\n",
    "effect = 0.03\n",
    "alpha = 0.05\n",
    "beta = 0.1\n",
    "\n",
    "\n",
    "def estimate_sample_size(effect, std, alpha, beta):\n",
    "    \"\"\"Оценка необходимого размер групп.\"\"\"\n",
    "    t_alpha = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    t_beta = stats.norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    var = 2 * std ** 2\n",
    "    sample_size = int((t_alpha + t_beta) ** 2 * var / (effect ** 2))\n",
    "    return sample_size\n",
    "\n",
    "\n",
    "# оценим необходимый размер групп\n",
    "sample_size = estimate_sample_size(effect * 100, 10, alpha, beta)\n",
    "print(f'sample_size = {sample_size}')\n",
    "# вычислим количество экспериментов\n",
    "count_exp = total_size / (sample_size * 2)\n",
    "print(f'count_exp = {count_exp:0.1f}')\n",
    "\n",
    "\n",
    "def estimate_ci_bernoulli(p, n, alpha=0.05):\n",
    "    \"\"\"Доверительный интервал для Бернуллиевской случайной величины.\"\"\"\n",
    "    t = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    std_n = np.sqrt(p * (1 - p) / n)\n",
    "    return p - t * std_n, p + t * std_n\n",
    "\n",
    "# Проверим, что при 21 эксперимента ошибки контролируются на заданных уровнях, а при 22 экспериментах нет.\n",
    "\n",
    "for count_exp in [21, 22]:\n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in tqdm(range(10000)):\n",
    "        a, b = np.random.normal(mean_, std_, (2, sample_size,))\n",
    "        b_effect = b * (1 + effect)\n",
    "        errors_aa.append(stats.ttest_ind(a, b).pvalue < alpha)\n",
    "        errors_ab.append(stats.ttest_ind(a, b_effect).pvalue >= alpha)\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    ci_first = estimate_ci_bernoulli(estimated_first_type_error, len(errors_aa))\n",
    "    ci_second = estimate_ci_bernoulli(estimated_second_type_error, len(errors_ab))\n",
    "    print(f'count_exp = {count_exp}')\n",
    "    print(f'sample_size = {sample_size}')\n",
    "    print(f'оценка вероятности ошибки I рода = {estimated_first_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_first[0]:0.4f}, {ci_first[1]:0.4f}]')\n",
    "    print(f'оценка вероятности ошибки II рода = {estimated_second_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_second[0]:0.4f}, {ci_second[1]:0.4f}]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b3feb-f844-4320-b90a-fcacb29510d3",
   "metadata": {},
   "source": [
    "## Задача 2. Количество параллельных экспериментов — 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60f171-c617-43ac-a283-474a731f4ff5",
   "metadata": {},
   "source": [
    "Задача похожа на предыдущую, только теперь __решение принимается не независимо для каждого эксперимента.__\n",
    "Например, у нас есть 5 текстов для маркетинговой рассылки, хотим проверить, какой эффективнее работает и работает ли вообще.\n",
    "\n",
    "__Алгоритм будет следующий:__\n",
    "1. Формируем непересекающиеся контрольные и экспериментальные группы для каждого из 5 вариантов.\n",
    "2. Проводим параллельно 5 экспериментов.\n",
    "3. С помощью метода Холма определяем, в каких экспериментах были статистически значимые отличия.\n",
    "4. Если значимых отличий не обнаружено, то говорим, что эффекта нет, все варианты отклоняем.\n",
    "5. Если значимые отличия обнаружены, то из вариантов со значимым эффектом выбираем вариант с наименьшим значением p-value, будем использовать его.\n",
    "\n",
    "Будем считать, что __совершена ошибка I рода__, если найдены значимые отличия, когда на самом деле их не было ни в одном из вариантов.\n",
    "\n",
    "Будем считать, что __совершена ошибка II рода__, если:\n",
    "- либо не найдено значимых отличий, когда на самом деле они были;\n",
    "- либо выбранный для дальнейшего использования вариант на самом деле был без эффекта, при этом были варианты с эффектом.\n",
    "\n",
    "__Параметры экспериментов:__\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Замечание: при оценке вероятности ошибки II рода нужно рассматривать худший сценарий, когда эффект есть только в одном из экспериментов. Чем в большем количестве экспериментов будет эффект, тем меньше будет вероятность ошибки II рода.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3228d6cb-9020-4c6c-bd70-b5708db89f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni_method(pvalues, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Carries out Bonferroni correction.\n",
    "\n",
    "    pvalues - list of pvalues.\n",
    "    alpha -  level of significance.\n",
    "    return - array of 0/1 flags indicating presence/absence of effect.\n",
    "    \"\"\"\n",
    "    pvalues = np.array(pvalues)\n",
    "    \n",
    "    return np.array(pvalues < (alpha / pvalues.shape[0])).astype(int)\n",
    "\n",
    "\n",
    "def holm_method(pvalues, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Carries out Holm method correction.\n",
    "\n",
    "    pvalues - list of pvalues.\n",
    "    alpha -  level of significance.\n",
    "    return - array of 0/1 flags indicating presence/absence of effect.\n",
    "    \"\"\"\n",
    "    n = len(pvalues)\n",
    "    \n",
    "    alphas = alpha / np.arange(n, 0, -1) #Array of alpha divided by indices.\n",
    "    sorted_indices = np.argsort(pvalues)\n",
    "    res = np.zeros(n)\n",
    "    \n",
    "    for (i, pv_i) in enumerate(sorted_indices):\n",
    "        if pvalues[pv_i] < alphas[i]:\n",
    "            res[pv_i] = 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return res.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83050d5-d763-4ea9-bbbd-0737873a472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ = holm_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a653f-b935-438a-8c72-b879b67f5834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
